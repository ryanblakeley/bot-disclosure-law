# Bot Disclosure Law

A law that requires all bots to be labeled as bots. Bot activity should always be labeled so that humans can easily distinguish it from human activity.

1. Any service which stores user accounts, must ensure that any account owned or accessed by a bot program must have a user name that ends in 'bot'.
2. All messages, comments, and audio clips must be labeled with the bot name.
3. User activity statistics like views, upvotes, downvotes, etc. must clearly designate the portion that is bots or not include bot activity in those statistics.
4. Generative art must be clearly attributed with the bot name.

## Terminology

- Bot: a program that acts like a human; a program that could be mistaken for a human or human behavior  
- Label: a registered user name that ends in 'bot' and is displayed at all times  
- Activity: something a human does that a bot may also do, including:
  - Natural language text
  - Natural language voice
  - Engagement statistics like views, upvotes, etc.
  - Generative art
  - Auction bidding

## Justification

Humans rely on information and networks with many other humans who they do not know personally. Our biggest networks are electronic, and in many cases it is difficult or impossible to tell if user activity is from real people or bots. Bots can be scaled up almost without limit, which means our communication networks and normal human intuitions about other humans are vulnerable to a new kind of manipulation.

Humans are resilient and flexible thinkers. But the most intelligent thing we evolved to be able to deal with is other humans. Bot intelligence is a threat we aren't evolved to respond to appropriately. We haven't been in the presence of something more capable and non-biological.

Bots are powerful and power can create good or bad situations. We should have the vigilance to not let powerful new agents be concealed as humans.

## Detecting violations

Detecting bots which are acting like people is not easy and will likely get more difficult as we advance into the future. Companies already implement terms of service agreements and monitor for violations. Strategies for monitoring and moderating content vary widely.

#### common strategies for detecting TOS violations
#### domain-specific strategies for detecting bots

## Determining guilty parties

Platforms are liable.

## Corrections and penalties

1. Bot shutdowns. Any bot that is proven to be acting without an appropriate label should be immediately shut down.
2. Service shutdowns. Any service that persistently or habitually mislabels activity should be penalized with a service shutdown period.
3. People who may have been affected should be periodically notified of aggregate statistics on mislabeled activity, and have the ability to investigate relevant records.

## Exceptions

There are times when a person may want to subject themself to **willful blindness**. For instance, a participant in a Turing test would want to not know beforehand whether they were talking to a bot or human. An exception waiver might be a good idea for such cases. However, these waivers should be for specific interactions or events and not for things like general user agreements that apply for an extended duration.

Consent renewal should be a restricted activity.
